/**
 * Ultra-Fast Optimized Itinerary Generation Route
 * Enterprise-grade performance with 3-5x speed improvements
 * 
 * @author Doniele Arys Antonio
 * @version 3.0.0
 */

import { NextRequest, NextResponse } from "next/server";
import { createHash } from "crypto";
import { optimizedPipeline } from "@/lib/performance/optimizedPipeline";
import { smartCacheManager } from "@/lib/performance/smartCacheManager";
import { ErrorHandler, ErrorType, ItineraryError } from "../../lib/errorHandler";
import { API_KEY } from "../../lib/config";
import { geminiModel } from "../../lib/config";

// Ultra-fast cache with aggressive optimization
const CACHE_TTL = 3 * 60 * 1000; // 3 minutes for faster updates
const MAX_CONCURRENT_REQUESTS = 8;
const REQUEST_TIMEOUT = 15000; // 15 seconds max

// Request deduplication map
const activeRequests = new Map<string, Promise<any>>();

/**
 * Ultra-fast cached itinerary generation
 */
async function generateOptimizedItinerary(requestBody: any, requestId: string) {
  return await ErrorHandler.withRetry(async () => {
    const { prompt, weatherData, interests, duration, budget, pax } = requestBody;

    if (!geminiModel) {
      throw new ItineraryError(ErrorType.GENERATION, "Gemini model not available", false, requestId);
    }

    // Parse duration efficiently
    const durationDays = duration ? parseInt(duration.toString().match(/\d+/)?.[0] || '1', 10) : null;

    // Execute optimized pipeline
    const { itinerary, metrics } = await optimizedPipeline.generateOptimized({
      prompt,
      interests: Array.isArray(interests) ? interests : [],
      weatherData,
      durationDays,
      budget: budget || 'mid-range',
      pax: pax || '2',
      model: geminiModel
    });

    console.log(`ðŸŽ¯ OPTIMIZED GENERATION: Completed in ${metrics.totalTime}ms with ${metrics.performance.efficiency}% efficiency`);
    
    return { 
      text: JSON.stringify(itinerary),
      metrics,
      cached: false,
      requestId
    };
  }, 2, 500); // Reduced retries and delay for faster response
}

export async function POST(req: NextRequest) {
  const requestStartTime = Date.now();
  
  try {
    const requestBody = await req.json();
    const { prompt } = requestBody;

    // Validate API key
    if (!API_KEY) {
      console.error("GOOGLE_GEMINI_API_KEY is missing!");
      return NextResponse.json({ 
        text: "", 
        error: "GOOGLE_GEMINI_API_KEY is missing on the server." 
      }, { status: 500 });
    }

    // Validate prompt
    if (!prompt) {
      return NextResponse.json({ 
        error: "Prompt is required" 
      }, { status: 400 });
    }

    // Generate stable request ID for deduplication
    const requestHash = createHash('sha256').update(JSON.stringify(requestBody)).digest('hex');
    const requestId = requestHash.substring(0, 8);

    // Check for duplicate concurrent requests
    if (activeRequests.has(requestHash)) {
      console.log(`ðŸ”„ DEDUPLICATION: Using existing request for "${prompt}"`);
      const result = await activeRequests.get(requestHash)!;
      return NextResponse.json({
        ...result,
        fromCache: true,
        deduplication: true
      });
    }

    // Check smart cache first
    const cacheKey = `optimized:${requestHash}`;
    const cachedResult = smartCacheManager.get(cacheKey);
    
    if (cachedResult) {
      const cacheTime = Date.now() - requestStartTime;
      console.log(`âš¡ CACHE HIT: Returned cached result in ${cacheTime}ms`);
      
      return NextResponse.json({
        ...cachedResult,
        fromCache: true,
        responseTime: cacheTime
      });
    }

    // Create generation promise with timeout
    const generationPromise = Promise.race([
      generateOptimizedItinerary(requestBody, requestId),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Request timeout')), REQUEST_TIMEOUT)
      )
    ]) as Promise<any>;

    // Store in active requests for deduplication
    activeRequests.set(requestHash, generationPromise);

    try {
      // Execute optimized generation
      const result = await generationPromise;
      
      // Cache the result for future requests
      smartCacheManager.set(cacheKey, result, CACHE_TTL);
      
      const totalTime = Date.now() - requestStartTime;
      console.log(`ðŸš€ OPTIMIZED ROUTE: Total request time ${totalTime}ms`);

      return NextResponse.json({
        ...result,
        responseTime: totalTime,
        optimized: true
      });

    } finally {
      // Clean up active request
      setTimeout(() => activeRequests.delete(requestHash), 5000);
    }

  } catch (e: any) {
    const requestId = createHash('sha256').update(JSON.stringify(req.body || {})).digest('hex').substring(0, 8);
    const errorDetails = ErrorHandler.handleError(e, requestId);
    
    console.error("Error in optimized itinerary generation:", errorDetails);
    
    return NextResponse.json({ 
      text: "", 
      error: errorDetails.message,
      errorType: errorDetails.type,
      requestId: errorDetails.requestId,
      retryable: errorDetails.retryable,
      optimized: false
    }, { status: 500 });
  }
}

/**
 * Health check endpoint for monitoring
 */
export async function GET(req: NextRequest) {
  const url = new URL(req.url);
  const action = url.searchParams.get('action');

  if (action === 'health') {
    const health = optimizedPipeline.getHealthMetrics();
    const cacheStats = smartCacheManager.getStats();
    
    return NextResponse.json({
      status: health.status,
      pipeline: health,
      cache: {
        hitRate: Math.round(cacheStats.hitRate * 100),
        totalEntries: cacheStats.totalEntries,
        averageResponseTime: Math.round(cacheStats.averageResponseTime)
      },
      timestamp: new Date().toISOString()
    });
  }

  if (action === 'metrics') {
    const cacheStats = smartCacheManager.getStats();
    
    return NextResponse.json({
      cache: cacheStats,
      activeRequests: activeRequests.size,
      performance: {
        averageResponseTime: Math.round(cacheStats.averageResponseTime),
        hitRate: Math.round(cacheStats.hitRate * 100),
        totalRequests: cacheStats.hits + cacheStats.misses
      },
      timestamp: new Date().toISOString()
    });
  }

  if (action === 'clear-cache') {
    smartCacheManager.clearAll();
    activeRequests.clear();
    
    return NextResponse.json({
      message: "Cache cleared successfully",
      timestamp: new Date().toISOString()
    });
  }

  return NextResponse.json({
    message: "Optimized Itinerary Generation API",
    version: "3.0.0",
    endpoints: {
      generate: "POST /",
      health: "GET /?action=health",
      metrics: "GET /?action=metrics",
      clearCache: "GET /?action=clear-cache"
    },
    optimizations: [
      "Ultra-fast activity search",
      "Parallel traffic processing", 
      "Smart multi-tier caching",
      "Request deduplication",
      "Geographic clustering",
      "Predictive cache warming"
    ]
  });
}
